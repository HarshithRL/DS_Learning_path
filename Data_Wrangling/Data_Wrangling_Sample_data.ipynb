{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce015cc",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f61c27",
   "metadata": {},
   "source": [
    "### What Is Data Wrangling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef416534",
   "metadata": {},
   "source": [
    "Data wrangling, also known as data munging or data cleaning, is the process of transforming and mapping raw data into a format that is suitable for analysis. This process involves cleaning and structuring raw data into a usable and organized form, making it easier to work with and analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e8f5f",
   "metadata": {},
   "source": [
    "#### Why it matters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95780ee",
   "metadata": {},
   "source": [
    "* Data wrangling enables you to gather data from multiple sources into a central spot.\n",
    "* Cleaning and converting data into a standard format enables you to perform cross-data set analytics.\n",
    "* Data wrangling prepares data by removing flawed and missing elements, readying it for data mining, and empowering businesses to make concrete, data-driven decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf25f12",
   "metadata": {},
   "source": [
    "### Common Steps Involved in Data wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce35f04",
   "metadata": {},
   "source": [
    "* Discovery : The first step helps you make sense of the data you're working with. You'll also need to keep the primary goal of the data analysis during this step\n",
    "* Structuring : This is the process in which you transform that raw data into a form appropriate for the analytical model you want to use to interpret the data.\n",
    "* Cleaning & Transformation :  tasks like standardising inputs, deleting empty cells, removing outliers, and deleting blank rows. Ultimately, the goal is to ensure the data is as error-free as possible. \n",
    "* Enriching : When you have transformed your data into a more usable state, you must determine if you have all the data you need for the project. If you don't, you can enrich it by adding values from other data sets\n",
    "* Validation : you might find some issues you need to address or that the data is ready to be analysed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc38dea",
   "metadata": {},
   "source": [
    "EXECUTION OF DATA WRANGLING STEPS IN PYSPARK (Simple Hands on Data Wrangling using Pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85cd1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import col, avg,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa9ce823",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Data_wrangling').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56967a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample data Set to work with data wrangling (Self generated)\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", StringType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Marks\", StringType(), True)\n",
    "])\n",
    "data = [('Aadi', 17, 'M', 90),\n",
    "        ('Deeksha', 17, 'F', 76),\n",
    "        ('Jincy', 18, 'F', 'NaN'),\n",
    "        ('Keerthi', 17, 'F', 74),\n",
    "        ('Harish', 18, 'M', 65),\n",
    "        ('Anu', 17, 'F', 'NaN'),\n",
    "        ('Ram', 17, 'M', 71)]\n",
    "\n",
    "df_sample = spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0616198",
   "metadata": {},
   "source": [
    "1. DATA EXPLORATION:\n",
    "Understanding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dad4f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-----+\n",
      "|   Name|Age|Gender|Marks|\n",
      "+-------+---+------+-----+\n",
      "|   Aadi| 17|     M|   90|\n",
      "|Deeksha| 17|     F|   76|\n",
      "|  Jincy| 18|     F|  NaN|\n",
      "|Keerthi| 17|     F|   74|\n",
      "| Harish| 18|     M|   65|\n",
      "|    Anu| 17|     F|  NaN|\n",
      "|    Ram| 17|     M|   71|\n",
      "+-------+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d286060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------------------+------+-----+\n",
      "|summary|Name|                Age|Gender|Marks|\n",
      "+-------+----+-------------------+------+-----+\n",
      "|  count|   7|                  7|     7|    7|\n",
      "|   mean|NULL| 17.285714285714285|  NULL|  NaN|\n",
      "| stddev|NULL|0.48795003647426616|  NULL|  NaN|\n",
      "|    min|Aadi|                 17|     F|   65|\n",
      "|    25%|NULL|               17.0|  NULL| 71.0|\n",
      "|    50%|NULL|               17.0|  NULL| 76.0|\n",
      "|    75%|NULL|               18.0|  NULL| 90.0|\n",
      "|    max| Ram|                 18|     M|  NaN|\n",
      "+-------+----+-------------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf6f8b",
   "metadata": {},
   "source": [
    "2. DEALING WITH MISSING VALUES:- \n",
    " Here, the null values present in the data  are removed and replaced with the mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f646374",
   "metadata": {},
   "source": [
    "Null values can be handeled many ways according to the Dataset\n",
    ",Here have replace the NULL value with 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98792f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Marks: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bf7abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg  marks obtained 75.2\n"
     ]
    }
   ],
   "source": [
    "#To find the mean of \"Marks\" column\n",
    "#We have to typecast  \"Marks\" to Integer ,As the Data type of column are String\n",
    "df_casted_dtypes = df_sample.withColumn(\"Marks\", df_sample[\"Marks\"].cast(IntegerType())).withColumn(\"Age\", df_sample[\"Age\"].cast(IntegerType()))\n",
    "avg_marks = df_casted_dtypes.select(avg(col('Marks'))).collect()[0][0]\n",
    "print(f'Avg  marks obtained {avg_marks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "857c725f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Marks: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_casted_dtypes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a058552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we obtained \"Avg_marks\" we replace the value with Null value in marks column \n",
    "df_null_replaced = df_sample.withColumn('Marks', when(col('Marks') == 'NaN', avg_marks).otherwise(col('Marks')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c066953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-----+\n",
      "|   Name|Age|Gender|Marks|\n",
      "+-------+---+------+-----+\n",
      "|   Aadi| 17|     M|   90|\n",
      "|Deeksha| 17|     F|   76|\n",
      "|  Jincy| 18|     F| 75.2|\n",
      "|Keerthi| 17|     F|   74|\n",
      "| Harish| 18|     M|   65|\n",
      "|    Anu| 17|     F| 75.2|\n",
      "|    Ram| 17|     M|   71|\n",
      "+-------+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_null_replaced.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60754047",
   "metadata": {},
   "source": [
    "3. RESHAPING THE DATA,\n",
    "The categorical values can be represented by a numerical value.\n",
    "As the data contain categorical values in the gender column, it can be reshaped by categorizing them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "897373f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_reshaped = df_null_replaced.withColumn('Gender', when(col('Gender') == 'M', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "696415f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-----+\n",
      "|   Name|Age|Gender|Marks|\n",
      "+-------+---+------+-----+\n",
      "|   Aadi| 17|     1|   90|\n",
      "|Deeksha| 17|     0|   76|\n",
      "|  Jincy| 18|     0| 75.2|\n",
      "|Keerthi| 17|     0|   74|\n",
      "| Harish| 18|     1|   65|\n",
      "|    Anu| 17|     0| 75.2|\n",
      "|    Ram| 17|     1|   71|\n",
      "+-------+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_column_reshaped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7d518",
   "metadata": {},
   "source": [
    "4. FILTERING,\n",
    "Here the data is restructured to the specific format by removing the unwanted data in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91a26645",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_filtered_df = df_column_reshaped.filter(df_column_reshaped['Marks'] >= 75).drop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5eb4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|   Name|Gender|Marks|\n",
      "+-------+------+-----+\n",
      "|   Aadi|     1|   90|\n",
      "|Deeksha|     0|   76|\n",
      "|  Jincy|     0| 75.2|\n",
      "|    Anu|     0| 75.2|\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sample_filtered_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449b8e9",
   "metadata": {},
   "source": [
    "## CONCLUSION \n",
    " To this end, It is understood how important data wrangling for data, \n",
    "and its potential to change the whole process upside down. \n",
    "The foundation of data science comes from good data. \n",
    "Hence optimized results can be obtained from optimized data to get optimized outcomes. \n",
    "Hence wrangle the data, before processing it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11eef18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
